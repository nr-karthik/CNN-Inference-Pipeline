{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9539a6d5-a06a-4f93-bee1-48298f64e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.vgg_quant_part2 import VGG16_quant_part2\n",
    "from models.quant_layer import QuantConv2d\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------- config ---------\n",
    "CKPT_PATH = \"result/Part2_VGG_2bitA_4bitW/best_vgg_2A4W.pth\"\n",
    "PREFIX    = \"systolic_array/tests/2_16x16_from_vgg/\"  # change if you want\n",
    "os.makedirs(PREFIX, exist_ok=True)\n",
    "\n",
    "NBIT_A = 2   # activations\n",
    "NBIT_W = 4   # weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a5eeb57-93a0-4999-971a-08185bd736aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qparams(alpha: torch.Tensor, nbit: int, signed: bool):\n",
    "    if signed:\n",
    "        qmax = (2**(nbit-1)) - 1\n",
    "        qmin = -(2**(nbit-1))\n",
    "    else:\n",
    "        qmax = (2**nbit) - 1\n",
    "        qmin = 0\n",
    "    delta = alpha / qmax\n",
    "    return qmin, qmax, delta\n",
    "\n",
    "\n",
    "def try_get_attr(obj, names):\n",
    "    for n in names:\n",
    "        if hasattr(obj, n):\n",
    "            return getattr(obj, n)\n",
    "    return None\n",
    "\n",
    "\n",
    "def to_broadcast(alpha: torch.Tensor, w: torch.Tensor):\n",
    "    if alpha.dim() == 0:\n",
    "        return alpha\n",
    "    if alpha.dim() == 1 and alpha.numel() == w.size(0):\n",
    "        return alpha.view(-1, 1, 1, 1)\n",
    "    return alpha.max()  # fallback scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203ac7f7-0773-4c11-a3d1-ffdfe22f1e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- load model ----------\n",
    "model = VGG16_quant_part2().to(DEVICE)\n",
    "ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n",
    "model.load_state_dict(ckpt[\"state_dict\"], strict=True)\n",
    "model.eval()\n",
    "\n",
    "# ---------- find squeezed 16x16 QuantConv2d ----------\n",
    "features = model.features\n",
    "squeezed_layer = None\n",
    "squeeze_idx = None\n",
    "for i, m in enumerate(features):\n",
    "    if isinstance(m, QuantConv2d) and m.in_channels == 16 and m.out_channels == 16:\n",
    "        squeezed_layer = m\n",
    "        squeeze_idx = i\n",
    "        break\n",
    "\n",
    "assert squeezed_layer is not None, \"Could not find 16x16 squeezed conv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a552efd5-7b29-40c6-88f4-388cf9e0b60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# ---------- hook to get activation feeding that layer ----------\n",
    "_cached = {}\n",
    "def pre_squeezed_hook(m, inp):\n",
    "    _cached[\"x_in\"] = inp[0].detach().to(DEVICE)\n",
    "\n",
    "h = squeezed_layer.register_forward_pre_hook(pre_squeezed_hook)\n",
    "\n",
    "# take one minibatch from CIFAR-10 test loader\n",
    "import torchvision, torchvision.transforms as T\n",
    "normalize = T.Normalize(mean=[0.491,0.482,0.447],\n",
    "                        std=[0.247,0.243,0.262])\n",
    "val_tf = T.Compose([T.ToTensor(), normalize])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=val_tf)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    xb, _ = next(iter(testloader))   # 1 image is enough\n",
    "    xb = xb.to(DEVICE)\n",
    "    _ = model(xb)                    # fills _cached[\"x_in\"]\n",
    "\n",
    "h.remove()\n",
    "x = _cached[\"x_in\"]      # shape [1, 16, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1423386-cab1-44cd-b920-a73793b060ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative psums BEFORE ReLU: 190\n",
      "Negative psums AFTER ReLU: 0\n"
     ]
    }
   ],
   "source": [
    "# --------- get quant params & quantize x, w ---------\n",
    "with torch.no_grad():\n",
    "    # weight: use quantized or derive from float\n",
    "    w_q = try_get_attr(squeezed_layer, [\"weight_q\"])\n",
    "    if w_q is None:\n",
    "        w_float = squeezed_layer.weight.detach()\n",
    "        w_alpha_fb = w_float.abs().max()\n",
    "        qmin_w, qmax_w, delta_w = qparams(w_alpha_fb, NBIT_W, signed=True)\n",
    "        w_int_tmp = torch.clamp(torch.round(w_float / delta_w), qmin_w, qmax_w)\n",
    "        w_q = (w_int_tmp * delta_w).to(w_float.dtype)\n",
    "    else:\n",
    "        w_q = w_q.detach()\n",
    "\n",
    "    # weight alpha\n",
    "    w_alpha = None\n",
    "    wq_mod = try_get_attr(squeezed_layer, [\"weight_quant\"])\n",
    "    if wq_mod is not None:\n",
    "        w_alpha = try_get_attr(wq_mod, [\"alpha\", \"scale\", \"s\", \"delta\", \"a\"])\n",
    "        if isinstance(w_alpha, (float, int)):\n",
    "            w_alpha = torch.tensor(w_alpha, device=DEVICE, dtype=w_q.dtype)\n",
    "        if w_alpha is not None:\n",
    "            w_alpha = w_alpha.detach()\n",
    "    if w_alpha is None:\n",
    "        w_alpha = w_q.abs().max()\n",
    "    w_alpha_b = to_broadcast(w_alpha, w_q)\n",
    "\n",
    "    # activation alpha\n",
    "    aq_mod = try_get_attr(squeezed_layer, [\"act_quant\"])\n",
    "    x_signed = bool(try_get_attr(aq_mod, [\"signed\"])) if aq_mod is not None else False\n",
    "    x_alpha = try_get_attr(aq_mod, [\"alpha\", \"scale\", \"s\", \"delta\", \"a\"])\n",
    "    if isinstance(x_alpha, (float, int)):\n",
    "        x_alpha = torch.tensor(x_alpha, device=DEVICE, dtype=x.dtype)\n",
    "    if x_alpha is None:\n",
    "        # after ReLU, unsigned\n",
    "        x_alpha = x.detach().max()\n",
    "    x_alpha = x_alpha.to(DEVICE)\n",
    "\n",
    "    # qparams\n",
    "    qmin_w, qmax_w, delta_w = qparams(w_alpha_b, NBIT_W, signed=True)\n",
    "    qmin_x, qmax_x, delta_x = qparams(x_alpha,   NBIT_A, signed=x_signed)\n",
    "\n",
    "    # quantize activations to 2-bit ints\n",
    "    x_int = torch.clamp(torch.round(x / delta_x), qmin_x, qmax_x).to(torch.int32)\n",
    "    # just use first sample\n",
    "    x_int0 = x_int[0]          # [16, H, W]\n",
    "    # pad 1 on each side → [16, 6, 6]\n",
    "    x_pad_int = F.pad(x_int0, (1, 1, 1, 1))   # (left,right,top,bottom)\n",
    "    \n",
    "    # quantize weights to 4-bit ints\n",
    "    w_int = torch.round(w_q / delta_w).to(torch.int32)  # [16, 16, 3, 3]\n",
    "\n",
    "    # integer conv (no bias) -> integer psum\n",
    "    stride  = squeezed_layer.stride\n",
    "    padding = squeezed_layer.padding\n",
    "    groups  = squeezed_layer.groups\n",
    "    x_pad_4d = x_pad_int.unsqueeze(0).float()        # [1, 16, 6, 6]\n",
    "    psum_int = F.conv2d(x_pad_4d, w_int.float(),\n",
    "                    bias=None, stride=1, padding=0)  # → [1, 16, 4, 4]\n",
    "    neg_before = (psum_int < 0).sum().item()\n",
    "    print(\"Negative psums BEFORE ReLU:\", neg_before)\n",
    "    psum_int = torch.clamp(psum_int, min=0)               # <<< ReLU here\n",
    "    neg_after = (psum_int < 0).sum().item()\n",
    "    print(\"Negative psums AFTER ReLU:\", neg_after)\n",
    "    psum0_int = psum_int[0]  # [16, 4, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6049d0bf-cc5c-416e-a423-c9521977a80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported act_tile0.txt, w_i0_o0_kij*.txt, out.txt to: systolic_array/tests/2_16x16_from_vgg/\n"
     ]
    }
   ],
   "source": [
    "# ---------- write act_tile0.txt ----------\n",
    "# match matt's conv_gen_2b_16x16.py format\n",
    "X = x_pad_int.view(16, -1).cpu()\n",
    "\n",
    "bit_precision = 2\n",
    "with open(os.path.join(PREFIX, 'act_tile0.txt'), 'w') as f:\n",
    "    f.write('#time0ic15[msb-lsb],time0ic6[msb-lst],....,time0ic0[msb-lst]#\\n')\n",
    "    f.write('#time1ic15[msb-lsb],time1ic6[msb-lst],....,time1ic0[msb-lst]#\\n')\n",
    "    f.write('#................#\\n')\n",
    "    for t in range(X.size(1)):        # time step (nij)\n",
    "        for ic in range(X.size(0)):   # IC index\n",
    "            v = int(X[15 - ic, t].item())   # reverse IC order\n",
    "            v = max(0, min(3, v))          # clamp to 2 bits\n",
    "            X_bin = f\"{v:02b}\"\n",
    "            for k in range(bit_precision):\n",
    "                f.write(X_bin[k])\n",
    "        f.write('\\n')\n",
    "\n",
    "\n",
    "# ---------- write weight files w_i0_o0_kij*.txt ----------\n",
    "W = w_int.view(16, 16, -1).cpu()   # [OC, IC, 9]\n",
    "\n",
    "def z4(x: int) -> str:\n",
    "    # same signed-4b encoding as conv_gen_2b_16x16.py\n",
    "    return f\"{x:04b}\" if x >= 0 else \"1\" + f\"{8 + x:03b}\"\n",
    "\n",
    "for kij in range(W.size(2)):       # 0..8\n",
    "    path = os.path.join(PREFIX, f\"w_i0_o0_kij{kij}.txt\")\n",
    "    with open(path, 'w') as f:\n",
    "        f.write('#oc0ic14[msb-lsb],oc0ic12[msb-lst],....,oc0ic0[msb-lst]#\\n')\n",
    "        f.write('#oc0ic15[msb-lsb],oc0ic13[msb-lst],....,oc0ic1[msb-lst]#\\n')\n",
    "        f.write('#................#\\n')\n",
    "        for oc in range(W.size(0)):    # per OC\n",
    "            # first line: even ICs (14,12,...,0) via i=1,3,...,15 and 15-i\n",
    "            for i in range(1, W.size(1), 2):\n",
    "                v = int(W[oc, 15 - i, kij].item())\n",
    "                v = max(-8, min(7, v))\n",
    "                bits = z4(v)\n",
    "                for b in bits:\n",
    "                    f.write(b)\n",
    "            f.write(\"\\n\")\n",
    "            # second line: odd ICs (15,13,...,1) via i=0,2,...,14 and 15-i\n",
    "            for i in range(0, W.size(1), 2):\n",
    "                v = int(W[oc, 15 - i, kij].item())\n",
    "                v = max(-8, min(7, v))\n",
    "                bits = z4(v)\n",
    "                for b in bits:\n",
    "                    f.write(b)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "\n",
    "# ---------- write out.txt ----------\n",
    "# P shape [nij, OC] after flatten + transpose, same as Matthew\n",
    "P = psum0_int.view(16, -1).T.cpu()    # [nij, 16]\n",
    "\n",
    "def z16(x: int) -> str:\n",
    "    # same 16-bit signed-ish encoding as util script\n",
    "    return f\"{x:016b}\" if x >= 0 else \"1\" + f\"{2**15 + x:015b}\"\n",
    "\n",
    "bit_precision = 16\n",
    "with open(os.path.join(PREFIX, 'out.txt'), 'w') as f:\n",
    "    f.write('#time0oc7[msb-lsb],time0oc6[msb-lst],....,time0oc0[msb-lst]#\\n')\n",
    "    f.write('#time0oc15[msb-lsb],time0oc14[msb-lst],....,time8oc0[msb-lst]#\\n')\n",
    "    f.write('#................#\\n')\n",
    "    for t in range(P.size(0)):       # per timestep\n",
    "        for oc in range(P.size(1)):  # per OC\n",
    "            idx = (7 - oc) if oc < 8 else (15 - oc + 8)  # 7..0, then 15..8\n",
    "            v = int(P[t, idx].item())\n",
    "            bits = z16(v)\n",
    "            for b in bits:\n",
    "                f.write(b)\n",
    "            if oc == 7:\n",
    "                f.write('\\n')   # extra mid-line break like Matthew's code\n",
    "        f.write('\\n')\n",
    "\n",
    "print(\"Exported act_tile0.txt, w_i0_o0_kij*.txt, out.txt to:\", PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e72130d9-9eb7-4ac5-996c-e493d426750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_int0: torch.Size([16, 4, 4])\n",
      "x_pad_int: torch.Size([16, 6, 6])\n",
      "timesteps: 36\n"
     ]
    }
   ],
   "source": [
    "print(\"x_int0:\", x_int0.shape)      # expect [16, 4, 4]\n",
    "print(\"x_pad_int:\", x_pad_int.shape)  # expect [16, 6, 6]\n",
    "print(\"timesteps:\", X.size(1))   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

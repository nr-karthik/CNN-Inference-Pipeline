{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3cc8982-7eff-4414-aeb6-cfcb9ef760da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, math, shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision, torchvision.transforms as T\n",
    "\n",
    "from models import *\n",
    "from models.vgg_quant_part2 import VGG16_quant_part2   \n",
    "from models.quant_layer import QuantConv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268ddef2-cfd2-4af7-b7ac-b956aa0b4f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Config -----------------\n",
    "DEVICE      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE  = 128\n",
    "PRINT_FREQ  = 100\n",
    "EPOCHS      = 200\n",
    "LR_BASE     = 0.1\n",
    "WEIGHT_DECAY= 1e-4\n",
    "\n",
    "# Part 2 spec\n",
    "NBIT_W      = 4    # weights 4-bit\n",
    "NBIT_A      = 2    # activations 2-bit\n",
    "RESULT_DIR  = \"result/Part2_VGG_2bitA_4bitW\"\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# This is the squeezed 16->16 conv index in model.features\n",
    "SQUEEZE_IDX = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c15595-18f3-4f3e-a4c7-f008b7752ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Helpers -----------------\n",
    "class AverageMeter:\n",
    "    def __init__(self): self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0; self.avg = 0; self.sum = 0; self.count = 0\n",
    "    def update(self, v, n=1):\n",
    "        self.val = v\n",
    "        self.sum += v * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / max(self.count, 1)\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def save_ckpt(state, is_best, fdir, tag):\n",
    "    p = os.path.join(fdir, f\"ckpt_{tag}.pth\")\n",
    "    torch.save(state, p)\n",
    "    if is_best:\n",
    "        shutil.copyfile(p, os.path.join(fdir, f\"best_{tag}.pth\"))\n",
    "\n",
    "MILESTONES = (60, 120, 150)\n",
    "GAMMA_LR   = 0.1\n",
    "def set_lr_epoch(optim, base_lr, epoch):\n",
    "    drops = sum(m <= epoch for m in MILESTONES)\n",
    "    lr = base_lr * (GAMMA_LR ** drops)\n",
    "    for g in optim.param_groups:\n",
    "        g[\"lr\"] = lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b109170a-6d26-4bfb-b720-a9bc1cde625f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Data -----------------\n",
    "normalize = T.Normalize(mean=[0.491,0.482,0.447],\n",
    "                        std=[0.247,0.243,0.262])\n",
    "train_tf = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "val_tf = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=train_tf)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=val_tf)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fab7649-855f-46d8-a669-6d044a77c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Model utils -----------------\n",
    "def set_bitwidth(model, nbit_w:int, nbit_a:int):\n",
    "    \"\"\"\n",
    "    Set bitwidth on all QuantConv2d layers.\n",
    "    Works with templates that have attributes:\n",
    "      - nbit_w, nbit_a, or\n",
    "      - weight_quant.bitwidth / act_quant.bitwidth\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, QuantConv2d):\n",
    "            if hasattr(m, 'nbit_w'): m.nbit_w = nbit_w\n",
    "            if hasattr(m, 'nbit_a'): m.nbit_a = nbit_a\n",
    "            if hasattr(m, 'weight_quant') and hasattr(m.weight_quant, 'bitwidth'):\n",
    "                m.weight_quant.bitwidth = nbit_w\n",
    "            if hasattr(m, 'act_quant') and hasattr(m.act_quant, 'bitwidth'):\n",
    "                m.act_quant.bitwidth = nbit_a\n",
    "    return model\n",
    "\n",
    "def build_vgg_part2():\n",
    "    # We already modified vgg_quant so one conv layer has 16 in/out channels\n",
    "    # and the BN after that layer is removed.\n",
    "    model = VGG16_quant_part2()          \n",
    "    model = set_bitwidth(model, NBIT_W, NBIT_A)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ----------------- Train / Validate -----------------\n",
    "def train_one_epoch(loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    top1  = AverageMeter()\n",
    "    st = time.time()\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "\n",
    "        prec1 = accuracy(out, y)[0]\n",
    "        losses.update(loss.item(), x.size(0))\n",
    "        top1.update(prec1.item(), x.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            print(f\"Epoch[{epoch}] Iter[{i}/{len(loader)}] \"\n",
    "                  f\"Loss {losses.val:.4f}({losses.avg:.4f})  \"\n",
    "                  f\"Acc {top1.val:.2f}%({top1.avg:.2f}%)\")\n",
    "\n",
    "def validate(loader, model, criterion):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    top1  = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            prec1 = accuracy(out, y)[0]\n",
    "            losses.update(loss.item(), x.size(0))\n",
    "            top1.update(prec1.item(), x.size(0))\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                print(f\"Val Iter[{i}/{len(loader)}] \"\n",
    "                      f\"Loss {losses.val:.4f}({losses.avg:.4f})  \"\n",
    "                      f\"Acc {top1.val:.2f}%({top1.avg:.2f}%)\")\n",
    "    print(f\"* Acc {top1.avg:.2f}%\")\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24f801c-24a1-406e-be5a-d2378c67d84f",
   "metadata": {},
   "source": [
    "### Report Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d2c1ca-296f-4189-a6e9-7f838a9e6383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== SOFTWARE ALPHA: ACTIVATION SPARSITY =====\n",
      "Evaluated 130 ReLU layers over 10 batches\n",
      "Average zero activation ratio : 68.32%\n",
      "Min zero activation ratio     : 48.48%\n",
      "Max zero activation ratio     : 98.79%\n",
      "\n",
      "Estimated MAC savings:\n",
      "~68.3% MACs can be skipped via zero-activation gating\n",
      "==============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Software Alpha: Activation Sparsity â†’ MAC Skipping Potential\n",
    "# Assumes:\n",
    "#  - DEVICE, testloader defined\n",
    "#  - validate() defined\n",
    "#  - VGG16_quant_part2 available\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# -------- Load trained 2A/4W model --------\n",
    "CKPT = \"result/Part2_VGG_2bitA_4bitW/best_vgg_2A4W.pth\"\n",
    "\n",
    "model = VGG16_quant_part2().to(DEVICE)\n",
    "ckpt = torch.load(CKPT, map_location=DEVICE)\n",
    "model.load_state_dict(ckpt[\"state_dict\"], strict=True)\n",
    "model.eval()\n",
    "\n",
    "# -------- Hook ReLU outputs --------\n",
    "relu_stats = []\n",
    "\n",
    "def relu_hook(m, inp, out):\n",
    "    z = (out == 0).float().mean().item()\n",
    "    relu_stats.append(z)\n",
    "\n",
    "hooks = []\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.ReLU):\n",
    "        hooks.append(m.register_forward_hook(relu_hook))\n",
    "\n",
    "# -------- Run a few validation batches --------\n",
    "NUM_BATCHES = 10\n",
    "with torch.no_grad():\n",
    "    for i, (x, _) in enumerate(testloader):\n",
    "        if i >= NUM_BATCHES:\n",
    "            break\n",
    "        x = x.to(DEVICE)\n",
    "        _ = model(x)\n",
    "\n",
    "for h in hooks:\n",
    "    h.remove()\n",
    "\n",
    "# -------- Report --------\n",
    "avg_zero = sum(relu_stats) / len(relu_stats)\n",
    "max_zero = max(relu_stats)\n",
    "min_zero = min(relu_stats)\n",
    "\n",
    "print(\"\\n===== SOFTWARE ALPHA: ACTIVATION SPARSITY =====\")\n",
    "print(f\"Evaluated {len(relu_stats)} ReLU layers over {NUM_BATCHES} batches\")\n",
    "print(f\"Average zero activation ratio : {avg_zero*100:.2f}%\")\n",
    "print(f\"Min zero activation ratio     : {min_zero*100:.2f}%\")\n",
    "print(f\"Max zero activation ratio     : {max_zero*100:.2f}%\")\n",
    "\n",
    "# -------- MAC skipping estimate --------\n",
    "print(\"\\nEstimated MAC savings:\")\n",
    "print(f\"~{avg_zero*100:.1f}% MACs can be skipped via zero-activation gating\")\n",
    "print(\"==============================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5167b476-e796-4c6f-ae7c-fb7177215bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
